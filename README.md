# Comments-Toxicity
This project focuses on detecting toxic comments using Natural Language Processing (NLP) and Deep Learning models. We use Recurrent Neural Networks (LSTM, BiLSTM) and Dense Neural Networks to classify comments as toxic or non-toxic. The goal is to build a model that can help automatically moderate online conversations by identifying harmful or not
